	Data Analysis conducted on the Iris Dataset

	Summary.
The analysis used as a source for this document (analysis.py) was conducted using Python and the Pandas, Numpy, Matplotlib, Seaborn, and Scikit-learn libraries. The dataset was imported from the UCI Machine Learning Repository and is a well-known dataset for classification tasks.
The dataset contained 150 samples of iris flowers, with 5 columns: sepal length, sepal width, petal length, petal width, and species (class). The dataset was used to conduct exploratory data analysis (EDA) and visualisation, as well as some machine learning tasks. Histogram, boxplot, scatterplot, PCA, pairplot, K-means clustering, correlation matrix, and linear regression analysis were conducted on the dataset, and the results of each were saved as a PNG file.

	Background.

Originally sourced by Anderson (1935), the Iris dataset has been used numerous times, with several different iterations available online. Some of these sources contain differing (and often noted as incorrect) data points, as noted in the UCI Machine Learning Repository (https://archive.ics.uci.edu/dataset/53/iris). The dataset contained 150 samples of Iris flower, each with five noted variables, four numeric (sepal and petal feature measurements), and one categorical (the three species), giving a total of 750 sample points throughout the entire dataset.
Fisher (1936) made the Iris dataset well known through his paper titled 'The Use of Multiple Measurements in Taxonomic Problems.' In the paper, the multivariate Iris dataset was used as an example of linear discriminant analysis. That is, a statistical method used to find a linear combination of features that can either characterise or separate two or more classes of objects or events (https://en.wikipedia.org/wiki/Linear_discriminant_analysis; https://www.ibm.com/think/topics/linear-discriminant-analysis).
Anderson (1935) originally collected the iris samples to study species variation and hybidisation. Anderson (1935) used the dataset to quantify the morphological differences and variation between Iris species, focussing on the evolution of the Versicolor species, and how it may have come about as a hybrid of the Setosa and Virginica Iris species. An interesting point about the dataset is that two of the three species, Iris Versicolor and Iris Virginica, were collected from the same pasture, on the same day, and measured using the same equipment. This is noteworthy for analysis, as Virginica and Versicolor often appear to converge and are not as easily separable as the Setosa species (histograms, scatter plots, etc.).
The Iris dataset has been extensively used as a training dataset, a learning dataset, and for developing machine learning techniques. The scikit-learn library in Python uses the Iris dataset for demonstration purposes and explains how algorithms can learn from data samples (features) to predict class labels (https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html; https://archive.ics.uci.edu/dataset/53/iris).
The Iris dataset also highlights the distinction between supervised and unsupervised learning. Supervised learning uses labeled data to train models for classification or regression, while unsupervised learning explores patterns or clusters in unlabeled data (https://www.ibm.com/think/topics/linear-discriminant-analysis). The iris dataset gives an example of supervised learning problems, particularly multi-class classification, where the goal is to predict an iris flower's species based on its measurements.
Although the dataset only includes flower measurements (sepal length/width and petal length/width) and not measurements for the entire plant, this focus reflects the expert judgment of Fisher and Anderson, who selected petal and sepal dimensions as meaningful discriminative features. This in turn highlights the importance of domain expertise in data preparation and model design, suggesting that more efficient analysis and models are built when field experts are involved (Domingos, 2012; Kuhn, and Johnson, 2013).

Despite its age and simplicity, the Iris dataset remains a central teaching tool for introducing classification problems in machine learning.

The shape of the dataset:
(150, 5)

The dataset contains 150 rows of data and 5 columns. The 5 columns are the species of isis flower (here noted as 'class'), and sepal length, sepal width, petal length, and petal width.
The first and last five rows of the dataset are printed below, as well as the column names within the dataset.

The first 5 rows of the dataset:
   sepal length  sepal width  petal length  petal width        class
0           5.1          3.5           1.4          0.2  Iris-setosa
1           4.9          3.0           1.4          0.2  Iris-setosa
2           4.7          3.2           1.3          0.2  Iris-setosa
3           4.6          3.1           1.5          0.2  Iris-setosa
4           5.0          3.6           1.4          0.2  Iris-setosa

The last 5 rows of the dataset:
     sepal length  sepal width  petal length  petal width           class
145           6.7          3.0           5.2          2.3  Iris-virginica
146           6.3          2.5           5.0          1.9  Iris-virginica
147           6.5          3.0           5.2          2.0  Iris-virginica
148           6.2          3.4           5.4          2.3  Iris-virginica
149           5.9          3.0           5.1          1.8  Iris-virginica

The column names of the dataset:
Index(['sepal length', 'sepal width', 'petal length', 'petal width', 'class'], dtype='object')

These print checks were conducted to ensure that the data was correctly imported and in the correct format.
The number of rows and columns in the dataset:
None

The number of missing values in the dataset:
sepal length    0
sepal width     0
petal length    0
petal width     0
class           0
dtype: int64

The number of duplicate rows in the dataset:
3

The data types of each column in the dataset:
sepal length    float64
sepal width     float64
petal length    float64
petal width     float64
class            object
dtype: object

Missing values were checked for in the dataset, there were none.
If there were missing values, the dataset would need to be cleaned and sorted further before any analysis could be conducted.
There were no missing values in this dataset, so further cleaning was unnecessary.

From the information table, it can be seen that where one column has categorical (object) data (class column - also referred to as species for this dataset) 
and the four other columns (sepal length, sepal width, petal length, and petal width) are of the float type (float64) (continuous variables) with non-Null entries. That is, there are no 0 / null~ entries in the dataset.

Duplicates were removed from the data using the drop_duplicates function.
The code used for this was: 	data = iris_df.drop_duplicates(subset=class.)
Value counts for each of the species:
class
Iris-setosa        50
Iris-versicolor    50
Iris-virginica     50
Name: count, dtype: int64

It can be seen that there are 50 samples for each of the three classes (species) of iris, setosa, versicolor, and virginica.

	Summary statistics for the whole dataset:
       sepal length  sepal width  petal length  petal width
count    150.000000   150.000000    150.000000   150.000000
mean       5.843333     3.054000      3.758667     1.198667
std        0.828066     0.433594      1.764420     0.763161
min        4.300000     2.000000      1.000000     0.100000
25%        5.100000     2.800000      1.600000     0.300000
50%        5.800000     3.000000      4.350000     1.300000
75%        6.400000     3.300000      5.100000     1.800000
max        7.900000     4.400000      6.900000     2.500000

The summary statistics for the whole dataset shows that there are 150 samples in the dataset for each of the variables, the value displayed is the non-missing values, and thus it can be verified that the dataset does not have any missing values. 
	Please Note: Summary statistics observations taken from my own work for the Principles of Data Analytics Module, with wording changed to match what was required for this project. Link: https://github.com/KaiiMenai/poda-tasks/blob/main/tasks.ipynb
The Mean, Standard Deviation (std), Minimum (min) and Maximum (max), and the Lower, Median, and Higher Inter-quartile Ranges (25%, 50%, and 75%, respectively) values are displayed for all four features (sepal length, sepal width, petal length, and petal width).
The Mean was calculated by dividing the sum of all the values (per feature) by the number of values (150 in this case). The mean for sepal length was 5.84 cm, sepal width was 3.05 cm, petal length was 3.76 cm, and for petal width was 1.20 cm. 

The Standard Deviation (std) is a measure of the spread of the data, that is, on average, how much the values deviate from the mean. Sepal length had a mean of 5.84 cm with a std of 0.83, therefore the majority of values deviate by 0.83 cm (+/-) from the mean. 
The mean for sepal width was 3.05 cm with a std of 0.43 cm, the sepal widths deviated by +/- 0.43 cm from the mean. The feature, sepal width, had less variability (std = 0.43) compared to that of sepal length (std = 0.83). 
For petal length, the mean was 3.76 cm with a std of 1.76 cm, thus most values for petal length deviated by 1.76 cm (+/-). Petal width had a mean of 1.20 cm with a std of 0.76 cm, the width of petals deviated by +/- 0.76 cm. 
The measurement with the largest deviation from the mean is the petal length (std = 1.76), this suggests that petal lengths vary more widely across samples compared to the other features.

In the Summary Statistics for each species, the count shows that there are 50 samples in the dataset for each, the values displayed is the non-missing value, suggesting that there are no missing values present in the dataset.

	Summary statistics for each species:

Setosa Statistics:
       sepal length  sepal width  petal length  petal width
count      50.00000    50.000000     50.000000     50.00000
mean        5.00600     3.418000      1.464000      0.24400
std         0.35249     0.381024      0.173511      0.10721
min         4.30000     2.300000      1.000000      0.10000
25%         4.80000     3.125000      1.400000      0.20000
50%         5.00000     3.400000      1.500000      0.20000
75%         5.20000     3.675000      1.575000      0.30000
max         5.80000     4.400000      1.900000      0.60000

Versicolor Statistics:
       sepal length  sepal width  petal length  petal width
count     50.000000    50.000000     50.000000    50.000000
mean       5.936000     2.770000      4.260000     1.326000
std        0.516171     0.313798      0.469911     0.197753
min        4.900000     2.000000      3.000000     1.000000
25%        5.600000     2.525000      4.000000     1.200000
50%        5.900000     2.800000      4.350000     1.300000
75%        6.300000     3.000000      4.600000     1.500000
max        7.000000     3.400000      5.100000     1.800000

Virginica Statistics:
       sepal length  sepal width  petal length  petal width
count      50.00000    50.000000     50.000000     50.00000
mean        6.58800     2.974000      5.552000      2.02600
std         0.63588     0.322497      0.551895      0.27465
min         4.90000     2.200000      4.500000      1.40000
25%         6.22500     2.800000      5.100000      1.80000
50%         6.50000     3.000000      5.550000      2.00000
75%         6.90000     3.175000      5.875000      2.30000
max         7.90000     3.800000      6.900000      2.50000

	Iris Setosa.

The mean for sepal length was AAA cm, sepal width was BBB cm, petal length was CCC cm, and for petal width the mean was DDD cm. The mean was calculated by dividing the sum of all the values (per feature) by the number of values (50 in this case, as it is done by species('class')).

The standard deviation (std) is a measure of the spread of the data, that is, on average, how much the values deviate from the mean. For sepal length the mean was AAA cm and the std was AAA, therefore most values deviated by AAA cm (+/-) from the mean.
The mean for sepal width was BBB cm and the std was BBB, so most values deviated by +/- BBB cm from the mean.
Petal length had a mean of

	Boxplots by Feature.

Boxplots were plotted for each of the four measured features (sepal length/width and petal length/width), the data in each of these four plots is separated by species. Boxplots make visualising range, potential outliers, the inter-quartile range, and the median of the data more easily.
There were nine outliers in total within the dataset between the four sepal/petal features. The Setosa species had three outliers in the data for petal length, and two outliers in the data for petal width. The Virginica species had one outlier for sepal length and two outliers for sepal width. The Versicolor species had the fewest number of outliers with only one outlier throughout the whole dataset, this outlier was for petal length.
On average, Setosa was found to have the shortest sepal length and widest sepal width. Setosa was also found to have the shortest petal length measurements and narrowest petal width. For Versicolor and Virginica, there were some differences visible in the measurements for the four features (sepal length/width, petal length/width), however, there were instances where the feature measurements converged, particularly for sepal length and sepal width. Petal length and petal width displayed differences between species, indicating that these feature measurements may be valuable for classification of Iris species.
(https://www.nickmccullum.com/python-visualization/boxplot/ , https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/data-presentation/box-and-whisker-plots.html).

	Histograms by Feature.

The histogram plots are all colour coded by species; blue for Setosa, orange for Versicolor, and green for Virginica.
From the histogram plot for sepal length by species, the Setosa species showed a normal distribution, with the majority of sepals being approximately 5.0 cm in length. The Versicolor species has a broad range of sepal lengths, with the most sepals being approximately 5.5 cm in length. The species with the largest range in length of sepals and longest average sepal length is the Virginica species.
For sepal width, it can be seen that overall, the data shows a normal distribution. Contrary to what was observed for sepal length, the narrowest sepal width is the Versicolor species, with the Virginica species being in the middle of the range. The Setosa species had the greatest width and the broadest range in values for sepal width.
Similar to what was observed for sepal length, for petal length Setosa was the species with the shortest average length and the smallest range in measurements. An average petal length of approximately 4.5 cm was observed for the Versicolor species and demonstrated a normal distribution. The Virginica species had, on average, the longest petal lengths, similar to what was observed for sepal lengths.
Setosa species had the narrowest petal width on average. The species with the mid-width measurement was the Versicolor species, with values between 1.0 cm and 2.0 cm. The widest petal widths were observed in the Virginica species.
It was observed that the sepal width and petal width for the Setosa species were contrary to one another. For the petal measurements of length and width, the Setosa species was the shortest and narrowest and the values for this species also separated away from the other two species.

	Scatterplots.

The plots are all colour coded by species; blue for Setosa, orange for Versicolor, and green for Virginica.





	Pairplot.

The plots are all colour coded by species; blue for Setosa, orange for Versicolor, and green for Virginica.





	Correlation Matrix.

The plots are all colour coded by species; blue for Setosa, orange for Versicolor, and green for Virginica.





	Principal Component Analysis (PCA).

The plots are all colour coded by species; blue for Setosa, orange for Versicolor, and green for Virginica.





	K-means Clustering.

The plots are all colour coded by species; blue for Setosa, orange for Versicolor, and green for Virginica.





	Logistic Regression Model

Although a linear regression model has previously been used to analyse the data, it is possible to predict a species based on the measurements taken from a flower through using a logistic regression model.
Using a Logistic Regression Model on the iris dataset is appropriate due to the relatively small size of the dataset (Log Regression Models work well with small, linearly separable datasets). The model is good for multi-class classification, as seen in the dataset with the 'species' classifications. When looking at the results of the logistic regression model, there are some things that should be taken into consideration. The iris dataset is relatively small, and when it is split on a species level, it has even fewer values. Although Logistic Regression Models work well on small datasets, splitting the dataset into multiple species creates a condensed dataset and may, not be representative of the wider population. (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html; https://www.ibm.com/think/topics/logistic-regression)

	Logistic Regression for Species Classification Results:
Accuracy: 1.0000

	Classification Report:
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        10
Iris-versicolor       1.00      1.00      1.00         9
 Iris-virginica       1.00      1.00      1.00        11

       accuracy                           1.00        30
      macro avg       1.00      1.00      1.00        30
   weighted avg       1.00      1.00      1.00        30


	Example Prediction (measurements in cm).

Predicted species for [5.1, 3.5, 1.4, 0.2]: Iris-setosa

For the iris dataset, the Logistic Regression Model achieves high accuracy (~97%), this is due to the simplicity and linear separability of the iris dataset. Accuracy for the Logistic Regression Model is calculated as the ratio of correct predictions to total predictions. The columns for precision and recall measure class specific performance in the model, and the f1-score column gives a balances metric for imbalanced classes (not a problem here as the iris dataset is balanced).
In the support column, it can be seen that the Verginica species has a value of 9, demonstrating a slightly lower recall, this is likely due to the overlap with Versicolor. As seen throughout previous testing on the dataset, the majority of the confusion in the dataset occurs between the Versicolor and Virginica species.
Initially upon looking at the Classification Report, it could be assumed that the results do not highlight anything. This report provides detailed insights into the performance of the model for each species, showing areas where the model performs well or struggles. However, due to the size of the dataset (150 samples), and then the test set being even smaller (30 samples), it makes it easier for the model to achieve perfect accuracy, this model produced an accuracy of 1.0 (perfect accuracy).
A linearly separable dataset is one that shows clear distinctions between classes, for the iris dataset that class difference is seen most clearly in the petal length/width. As the iris dataset is balanced, with an equal number of samples for each class (50), the risk of bias in the model is reduced. In order to improve accuracy and reliability, the model should be rerun a number of times using different splits of the data, this is called cross-validation.

	Confusion Matrix.

A confusion matrix was plotted to visualise the results. The confusion matrix is a performance evaluation tool for classification models. It provides a summary of the prediction results by comparing the actual values (rows) against the predicted values (columns).
The confusion matrix helps with understanding how well the logistic regression model classifies the different species of iris and whether there are any species that are more prone to misclassification (https://www.analyticsvidhya.com/blog/2020/04/confusion-matrix-machine-learning/).
To interpret the matrix, the structure and values within the matrix are important to understand what it shows. The rows within the matrix represent the Actual Classes (actual species of iris), whilst the columns represent the Predicted Classes (predicted species from the model output).
The matrix contains a number of values, on the diagonal line (from top left to bottom right) the values denote the Correct Predictions, where the actual and predicted classes (species) match. All other values from the diagonal are those denoting Misclassifications, where the actual and predicted species differ.
Although the Logistic Regression Model gives a value for Accuracy (1.000) for species classification, the classification report and confusion matrix aid in giving a clearer picture of the data and the accuracy of predictions made with the model.

	Conclusion.

The analysis of the Iris dataset has provided valuable insights into the relationships between features (sepal length/width, petal length/width) and the target variable (species).
The dataset was found to be balanced, with 50 samples for each of the three species (Setosa, Versicolor, Virginica). The summary statistics showed that there were no missing values in the dataset, and the features had different means and standard deviations. The box plots and histograms provided visualisations of the distribution of features by species, and the scatter plots showed the relationships between features and the target variable.
For a number of plots (histograms, scatter plots, linear regression, box plots) the Setosa species clearly clusters separately to the Versicolor and Virginica species, for both sepal and petal features. For petal features, all species separated from one another (with some minor overlap visible between the Versicolor and Virginica species), indicating that petal features were more distinguishable between species, and thus would be more useful in classification.
The PCA and K-means clustering techniques were used to reduce the dimensionality of the data and identify clusters in the data, respectively. Following the principal component analysis (PCA) the observations about petal features being more distinguishable between species, commpared to sepal features was solidified as it was found that PC1 (first principal component) was responsible for 72.8 % of the variability seen within the data, the PC1 was referring to the petal length and width features.
The feature correlation matrix heat map also displayed the difference between species based onn petal features, where petal length vs petal width resulted in r = 0.96 indicating that the petal length and width showed a strong positive correlation and that their measurements often varied together. The Logistic Regression (classification techniques) were used to predict the species of iris flowers based on their features, and the Linear Regression (regression techniques) were used to predict continuous values based on features.
For the linear regression (LRM) analysis, petal length vs petal width gave an R^2 value of 0.93, indicating that most of the variance in petal width can be explained by petal length. Some predictions were made for petal width following an 80 - 20 split in the data for training and testing, respectively. The analysis has also shown that the dataset is suitable for classification and regression tasks, and the techniques used have provided valuable insights into the relationships between features and the target variable.
The analysis has demonstrated that the features (sepal length/width, petal length/width) are valuable for classification of iris species, and the techniques used have provided valuable insights into the relationships between features and the target variable. However, in order to have a more reliable method for predicting the species using a linear regression (or logistic regression) model, a larger sample population is essential in order to accurately visualise and calculate the nuances between such species based on their features.

In terms of model accuracy, reliability, and consistent repeatability the size of the dataset may be considered a limiting factor. However, the data does efficiently demonstrate what a linear based dataset can show through various forms of analysis.



	References.

	Academic Sources

Anderson, E. (1935) ‘The irises of the Gaspé peninsula’, Bulletin of the American Iris Society, 59, pp. 2–5.

Cheeseman, P., Kelly, J., Self, M. and Taylor, W. (1988) AUTOCLASS II conceptual clustering system finds 3 classes in the data, MLC Proceedings, pp. 54–64. Available at: https://cdn.aaai.org/AAAI/1988/AAAI88-108.pdf

Dasarathy, B.V. (1980) ‘Nosing around the neighborhood: a new system structure and classification rule for recognition in partially exposed environments’, IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-2(1), pp. 67–71. Available at: https://www.academia.edu/30910064/Nosing_Around_the_Neighborhood_A_New_System_Structure_and_Classification_Rule_for_Recognition_in_Partially_Exposed_Environments

Domingos, P. (2012) ‘A few useful things to know about machine learning’, Communications of the ACM, 55(10), pp. 78–87. Available at: https://dl.acm.org/doi/10.1145/2347736.2347755

Duda, R.O. and Hart, P.E. (1973) Pattern Classification and Scene Analysis. New York: John Wiley & Sons. Available at: https://www.semanticscholar.org/paper/Pattern-classification-and-scene-analysis-Duda-Hart/b07ce649d6f6eb636872527104b0209d3edc8188

Fisher, R.A. (1936) ‘The use of multiple measurements in taxonomic problems’, Annual Eugenics, 7(Part II), pp. 179–188. Available at: https://onlinelibrary.wiley.com/doi/10.1111/j.1469-1809.1936.tb02137.x

Fisher, R.A. (1950) Contributions to Mathematical Statistics. New York: Wiley & Co.

Gates, G.W. (1972) ‘The reduced nearest neighbor rule’, IEEE Transactions on Information Theory, 18(3), pp. 431–433. Available at: https://ieeexplore.ieee.org/document/1054809

Hamilton, K.M. (2022) Drug resistance and susceptibility in sheep nematodes: fitness and the role of anthelmintic combinations in resistance management. PhD Thesis. University College Dublin, Teagasc, and AgResearch.

James, G., Witten, D., Hastie, T. and Tibshirani, R. (2013) An Introduction to Statistical Learning. New York: Springer. Available at: https://link.springer.com/book/10.1007/978-1-0716-1418-1

Jolliffe, I.T. and Cadima, J. (2016) ‘Principal component analysis: a review and recent developments’, Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, 374(2065), pp. 20150202. Available at: https://pubmed.ncbi.nlm.nih.gov/26953178/

Kuhn, M. and Johnson, K. (2013) Applied Predictive Modeling. Springer. Available at: https://link.springer.com/book/10.1007/978-1-4614-6849-3



	Information Sources (Non-Academic)

Analytics Vidhya (2020) ‘Confusion matrix in machine learning’. Available at: https://www.analyticsvidhya.com/blog/2020/04/confusion-matrix-machine-learning/

Analytics Vidhya (2024) ‘Pair plots in machine learning’. Available at: https://www.analyticsvidhya.com/blog/2024/02/pair-plots-in-machine-learning/

Built In (no date) ‘Seaborn pairplot’. Available at: https://builtin.com/articles/seaborn-pairplot

Bytemedirk (no date) ‘Mastering iris dataset analysis with Python’. Available at: https://bytemedirk.medium.com/mastering-iris-dataset-analysis-with-python-9e040a088ef4

Datacamp (no date) ‘Simple linear regression tutorial’. Available at: https://www.datacamp.com/tutorial/simple-linear-regression

Datatab (no date) ‘Linear regression tutorial’. Available at: https://datatab.net/tutorial/linear-regression

GeeksforGeeks (no date) ‘Exploratory data analysis on iris dataset’. Available at: https://www.geeksforgeeks.org/exploratory-data-analysis-on-iris-dataset/

GeeksforGeeks (no date) ‘How to show first/last n rows of a dataframe’. Available at: https://stackoverflow.com/questions/58260771/how-to-show-firstlast-n-rows-of-a-dataframe

GeeksforGeeks (no date) ‘Iris dataset’. Available at: https://www.geeksforgeeks.org/iris-dataset/

GeeksforGeeks (no date) ‘Interpretations of histogram’. Available at: https://www.geeksforgeeks.org/interpretations-of-histogram/

GeeksforGeeks (no date) ‘ML mathematical explanation of RMSE and R-squared error’. Available at: https://www.geeksforgeeks.org/ml-mathematical-explanation-of-rmse-and-r-squared-error/

GeeksforGeeks (no date) ‘Python basics of pandas using iris dataset’. Available at: https://www.geeksforgeeks.org/python-basics-of-pandas-using-iris-dataset/

Gist (no date) ‘Iris dataset CSV’. Available at: https://gist.githubusercontent.com/

How.dev (no date) ‘How to perform the ANOVA test in Python’. Available at: https://how.dev/answers/how-to-perform-the-anova-test-in-python

IBM (no date) ‘Introduction to linear discriminant analysis’. Available at: https://www.ibm.com/think/topics/linear-discriminant-analysis

IBM (no date) ‘Linear regression’. Available at: https://www.ibm.com/think/topics/linear-regression

IBM (no date) ‘Logistic regression’. Available at: https://www.ibm.com/think/topics/logistic-regression

Investopedia (no date) ‘R-squared’. Available at: https://www.investopedia.com/terms/r/r-squared.asp

Kachiann (no date) ‘A beginners guide to machine learning with Python: Iris flower prediction’. Available at: https://medium.com/@kachiann/a-beginners-guide-to-machine-learning-with-python-iris-flower-prediction-61814e095268

Kulkarni, M. (no date) ‘Heatmap analysis using Python seaborn and matplotlib’. Available at: https://medium.com/@kulkarni.madhwaraj/heatmap-analysis-using-python-seaborn-and-matplotlib-f6f5d7da2f64

Medium (no date) ‘Exploratory data analysis of iris dataset’. Available at: https://medium.com/@nirajan.acharya777/exploratory-data-analysis-of-iris-dataset-9c0df76771df

Medium (no date) ‘Pairplot visualization’. Available at: https://medium.com/analytics-vidhya/pairplot-visualization-16325cd725e6

Medium (no date) ‘Regression model evaluation metrics’. Available at: https://medium.com/%40brandon93.w/regression-model-evaluation-metrics-r-squared-adjusted-r-squared-mse-rmse-and-mae-24dcc0e4cbd3

Medium (2023) 'Scikit-learn, the iris dataset, and machine learning: the journey to a new skill'. Medium. Available at: https://3tw.medium.com/scikit-learn-the-iris-dataset-and-machine-learning-the-journey-to-a-new-skill-c8d2f537e087

Mizanur (no date) ‘Cleaning your data: handling missing and duplicate values’. Available at: https://mizanur.io/cleaning-your-data-handling-missing-and-duplicate-values/

Newcastle University (no date) ‘Box and whisker plots’. Available at: https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/data-presentation/box-and-whisker-plots.html

Nick McCullum (no date) ‘Python visualization: boxplot’. Available at: https://www.nickmccullum.com/python-visualization/boxplot/

Numpy (no date) ‘numpy.polyfit’. Available at: https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html

Pandas (no date) ‘pandas.read_csv’. Available at: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html

Python Documentation (no date) ‘Built-in types’. Available at: https://docs.python.org/3/library/stdtypes.html

ResearchGate (no date) ‘Classification of Iris Flower Dataset using Different Algorithms’. Available at: https://www.researchgate.net/publication/367220930_Classification_of_Iris_Flower_Dataset_using_Different_Algorithms

RSS (no date) ‘Common statistical terms’. Available at: https://rss.org.uk/resources/statistical-explainers/common-statistical-terms/

Scikit-learn (no date) ‘Classification report’. Available at: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html

Scikit-learn (no date) ‘LabelEncoder’. Available at: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html

Scikit-learn (no date) ‘LinearRegression’. Available at: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html

Scikit-learn (no date) ‘LogisticRegression’. Available at: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html

Scikit-learn (no date) ‘PCA example with iris dataset’. Available at: https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_iris.html

Scikit-learn Documentation (2021) ‘Plot Iris Dataset Example’. Available at: https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html

Seaborn (no date) ‘Pairplot’. Available at: https://seaborn.pydata.org/generated/seaborn.pairplot.html

Seaborn (no date) ‘Regplot’. Available at: https://seaborn.pydata.org/generated/seaborn.regplot.html

Seaborn (no date) ‘Scatterplot’. Available at: https://seaborn.pydata.org/generated/seaborn.scatterplot.html

Slidescope (no date) ‘ANOVA example using Python pandas on iris dataset’. Available at: https://slidescope.com/anova-example-using-python-pandas-on-iris-dataset/#:~:text=We%20then%20convert%20the%20dataset,p-value%20for%20the%20test

Stack Overflow (no date) ‘How to show first/last n rows of a dataframe’. Available at: https://stackoverflow.com/questions/58260771/how-to-show-firstlast-n-rows-of-a-dataframe

Toxigon (no date) ‘Best practices for data cleaning and preprocessing’. Available at: https://toxigon.com/best-practices-for-data-cleaning-and-preprocessing

Toxigon (no date) ‘Guide to data cleaning’. Available at: https://toxigon.com/guide-to-data-cleaning

Toxigon (no date) ‘Introduction to seaborn for data visualization’. Available at: https://toxigon.com/introduction-to-seaborn-for-data-visualization

Toxigon (no date) ‘Seaborn data visualization guide’. Available at: https://toxigon.com/seaborn-data-visualization-guide

UCI Machine Learning Repository (2025) ‘Iris Dataset’. Available at: https://archive.ics.uci.edu/dataset/53/iris

WV State University (no date) ‘Scholarly vs. non-scholarly articles’. Available at: https://wvstateu.libguides.com/c.php?g=813217&p=5816022

Wikipedia (no date) ‘Linear discriminant analysis’. Available at: https://en.wikipedia.org/wiki/Linear_discriminant_analysis

END OF ANALYSIS DOCUMENT
