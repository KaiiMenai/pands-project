{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Commentary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "author: Kyra Menai Hamilton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document, I will give a further commentary on each part of the code I have written in analysis.py. Please refer to the analysis.py python file for the analysis code in a more cohesive piece. In this file it will be broken down and annotated as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Importing the modules and specific tools for the data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any analysis can be started, importing the correct tools is essential. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the importing of module libraries the dataset needed to be sourced. This was sourced from the UC Irvine Machine Learning Repository and imported using the python import button. firt it was necessary to run the 'pip install ucimlrepo' in the terminal to install the ucimlrepo package. Following this the dataset was imported. It is important to know that the dataset was initially not imported as a DataFrame, rather as a file containing metadata and variables. the dataset was renamed 'iris' to make it easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset, fetch the dataset, define the data (as pandas dataframes), print metadata, and print the variable information to check that it worked.\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "iris = fetch_ucirepo(id=53) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing with the analysis, saving the dataset as a .csv file for future reference was important. The dataset needed to be converted and for this to happen. First the x and y frames of the data were extracted, these were the features and targets, respectively. Then the metadata and variables were checked and changed to note form. Finally the features and targets were combined into a dataframe 'iris_df' and this was converted to a .csv using the '.to_csv' function. Upon successful completion \"Iris dataset has been successfully exported to a CSV!\" would be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data - extracting x and y (as pandas dataframes) \n",
    "x = iris.data.features \n",
    "y = iris.data.targets \n",
    "\n",
    "# metadata - print was to check\n",
    "# print(iris.metadata) \n",
    "\n",
    "# variable information - print was to check\n",
    "# print(iris.variables) \n",
    "\n",
    "# Combine the features and targets into a single DataFrame (df) so it can be exported as a CSV\n",
    "iris_df = pd.concat([x, y], axis=1)\n",
    "\n",
    "# Exporting the DataFrame (df) to a CSV file\n",
    "iris_df.to_csv('D:/Data_Analytics/Modules/PandS/pands-project/iris.csv', index=False)\n",
    "print(\"Iris dataset has been successfully exported to a CSV!\") # Output - Iris dataset has been successfully exported to a CSV!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to continuing with the data analysis, to ensure ease of data manipulation, the data for analysis was then inputted from the iris dataframe saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv('D:/Data_Analytics/Modules/PandS/pands-project/iris.csv')\n",
    "\n",
    "print(iris_df) # This will print the dataframe into the terminal and also gi ve a brief summary of (150 rows x 5 columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
